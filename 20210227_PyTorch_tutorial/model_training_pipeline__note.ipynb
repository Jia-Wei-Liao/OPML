{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"model_training_pipeline__note.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"loose-contributor"},"source":["# Import Packages"],"id":"loose-contributor"},{"cell_type":"code","metadata":{"id":"lined-charity"},"source":["import os, torch\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","from utils import *"],"id":"lined-charity","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"suspected-champagne"},"source":["# Setup"],"id":"suspected-champagne"},{"cell_type":"code","metadata":{"id":"valued-politics"},"source":["csv_file = \"train.csv\"\n","data_list = pd.read_csv(csv_file)\n","data_root = \"train\"\n","file = \"{}.jpg\"\n","data_list"],"id":"valued-politics","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"center-seminar"},"source":["# 0. Pipeline Illustration\n","關於訓練模型，我們有幾個步驟要做：\n","1. 讀資料、建構 Dataset 及 DataLoader\n","2. 定義 model, optimizer, loss\n","3. training and validation"],"id":"center-seminar"},{"cell_type":"markdown","metadata":{"id":"surprising-concrete"},"source":["# 1. Load Data and Construct Dataset, DataLoader"],"id":"surprising-concrete"},{"cell_type":"markdown","metadata":{"id":"living-poultry"},"source":["### 1.1. Load JPG, JPEG, PNG\n","因為我們的影像是 JPEG 檔，所以我們來學如何讀這系列的檔案\n","\n","##### Note.\n","這系列の檔案類型都是色彩強度在 [0, 255] 的影像"],"id":"living-poultry"},{"cell_type":"code","metadata":{"id":"musical-blackberry"},"source":["data_list.StudyInstanceUID"],"id":"musical-blackberry","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"labeled-episode"},"source":["filename = \"1.2.826.0.1.3680043.8.498.16451034714945708059993280774682419855.jpg\"\n","filename"],"id":"labeled-episode","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"unlike-overhead"},"source":["data_root + \"/\" + filename"],"id":"unlike-overhead","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"interim-devil"},"source":["root = \"train/\"\n","root + \"/\" + filename"],"id":"interim-devil","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"therapeutic-cannon"},"source":["os.path.join(root, filename)"],"id":"therapeutic-cannon","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"spatial-sweden"},"source":["os.path.join(data_root, filename)"],"id":"spatial-sweden","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"prerequisite-while"},"source":["example_image = np.random.choice(data_list.StudyInstanceUID)\n","\n","os.path.join(data_root, example_image)"],"id":"prerequisite-while","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"compound-reach"},"source":["example_image = np.random.choice(data_list.StudyInstanceUID)\n","path = os.path.join(data_root, file.format(example_image))\n","path"],"id":"compound-reach","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"musical-channels"},"source":["image = Image.open(path)\n","image"],"id":"musical-channels","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cultural-northern"},"source":["array = np.array(image)\n","print(f\"shape = {array.shape}\")\n","np.unique(array)"],"id":"cultural-northern","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"seeing-hughes"},"source":["import nibabel as nib\n","# define path\n","nifti = nib.load(path)\n","array = nifti.get_fdata()"],"id":"seeing-hughes","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"religious-dakota"},"source":["### 1.2. Pytorch Dataset and DataLoader\n","Pytorch Dataset 是一種 iterable（熟悉吧？）\n","1. 它必須繼承 Pytorch 的 Dataset class\n","2. 是一個 iterable class，會一個一個吐出你的 data\n","\n","至於 data 要用什麼形式包裝他就不限制了。\n","不過我想給大家一個管理 data 的建議：一個 data 用一個 dictionary 包裝。"],"id":"religious-dakota"},{"cell_type":"code","metadata":{"id":"surprising-discovery"},"source":["# data_list.iloc[0, 0]\n","# data_list.loc[0, \"StudyInstanceUID\"]"],"id":"surprising-discovery","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"enhanced-equilibrium"},"source":["example_index = 0\n","data_list.iloc[example_index, 1:-1]"],"id":"enhanced-equilibrium","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"growing-indonesian"},"source":["data_list.iloc[example_index, 1:-1].values"],"id":"growing-indonesian","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wicked-wheat"},"source":["np.array(data_list.iloc[example_index, 1:-1])"],"id":"wicked-wheat","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"humanitarian-palace"},"source":["np.array(data_list.iloc[example_index, 1:-1], dtype=\"float32\")"],"id":"humanitarian-palace","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cleared-finger"},"source":["example_index = 0\n","data = {\n","    \"patient_id\": data_list.iloc[example_index, -1],\n","    \"image\": os.path.join(data_root, file.format(data_list.iloc[example_index, 0])),\n","    \"label\": np.array(data_list.iloc[example_index, 1:-1], dtype=\"float32\")\n","}\n","data"],"id":"cleared-finger","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"informational-bride"},"source":["### 1.3. Your Trun!\n","請你動手寫一個名為 RANZCR 的 Pytorch Dataset。\n","1. 繼承 torch.utils.data.Dataset (Hint: 在開頭的 import 環節，我已經幫你把它 import 成 Dataset 了，繼承 Dataset 並 initialize 就好）\n","2. initialize 兩個字串 data_root 和 csv_file（建議按照順序）\n","  * 把 csv_file 讀成 pandas DataFrame 作為 attribute\n","  * 直接把 data_root 存成字串，用來讀串接影像名稱\n","3. 用你的方式寫一個 iterable：\n","  * 放到迴圈時，每一次迭代吐一組資料（即一個 dictionary 如上）\n","  * 可以取長度\n","  * 可以多次放到迴圈裡面使用"],"id":"informational-bride"},{"cell_type":"code","metadata":{"id":"emotional-ethernet"},"source":["import tensorflow as tf\n","tf. ...\n","import tensorflow\n","tensorflow. ..."],"id":"emotional-ethernet","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"devoted-documentary"},"source":["# your code here\n","class RANZCR(Dataset):\n","    def __init__(self, data_root, csv_file):\n","        super(RANZCR, self).__init__()\n","        self.data_root = data_root\n","        self.data_list = pd.read_csv(csv_file)\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","\n","    def __getitem__(self, i):\n","        data = {\n","            \"patient_id\": self.data_list.iloc[i, -1],\n","            \"image\": os.path.join(self.data_root, file.format(self.data_list.iloc[i, 0])),\n","            \"label\": np.array(self.data_list.iloc[i, 1:-1], dtype=\"float32\")\n","        }\n","\n","        return data"],"id":"devoted-documentary","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"forward-retrieval"},"source":["check_answer = True\n","\n","if check_answer:\n","    dataset = RANZCR(data_root, csv_file)\n","\n","    for data in dataset:\n","        print(data)\n","        break"],"id":"forward-retrieval","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rural-vertex"},"source":["### 1.4. Data Transform\n","你肯定注意到了，我們讀進來的資料只有檔名，不可能直接拿來 train。\n","這時我們需要一連串的 transforms 來讓資料從檔名開始經歷他的奇幻旅程，這中間你愛加多少 data augmentation 都隨你開心。"],"id":"rural-vertex"},{"cell_type":"code","metadata":{"id":"recent-aquarium"},"source":["# 帶大家寫 Tranform 以及把 Dataset 修成有 transform 的版本\n","\n","class RANZCR(Dataset):\n","    def __init__(self, data_root, csv_file, transform=None):\n","        super(RANZCR, self).__init__()\n","        self.data_root = data_root\n","        self.data_list = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.file = \"{}.jpg\"\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","\n","    def __getitem__(self, i):\n","        data = {\n","            \"patient_id\": self.data_list.iloc[i, -1],\n","            \"image\": os.path.join(self.data_root, file.format(self.data_list.iloc[i, 0])),\n","            \"label\": np.array(self.data_list.iloc[i, 1:-1], dtype=\"float32\")\n","        }\n","\n","        if self.transform is not None:\n","            data = self.transform(data)\n","\n","        return data"],"id":"recent-aquarium","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swiss-fundamentals"},"source":["class JPGLoader(Transform):\n","    def __init__(self, keys):\n","        self.keys = keys\n","\n","    def __call__(self, data):\n","        for key in self.keys:\n","            if key in data:\n","                path = data[key]\n","                data[key] = Image.open(path)\n","\n","            else:\n","                raise KeyError(f\"{key} is a key of {data}.\")\n","\n","        return data"],"id":"swiss-fundamentals","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"brazilian-longer"},"source":["raise IndexError()"],"id":"brazilian-longer","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dramatic-wiring"},"source":["raise KeyError()"],"id":"dramatic-wiring","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"provincial-amount"},"source":["raise StopIteration()"],"id":"provincial-amount","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oriental-invasion"},"source":["raise RuntimeError()"],"id":"oriental-invasion","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lonely-curve"},"source":["dataset = RANZCR(data_root, csv_file, transform=JPGLoader(keys=[\"imae\"]))\n","\n","for data in dataset:\n","    print(data)\n","    break"],"id":"lonely-curve","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"funky-shopping"},"source":["dataset = RANZCR(data_root, csv_file, transform=JPGLoader(keys=[\"image\"]))\n","\n","for data in dataset:\n","    print(data)\n","    break"],"id":"funky-shopping","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"biblical-yahoo"},"source":["data[\"image\"].shape"],"id":"biblical-yahoo","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"contained-billy"},"source":["image = data[\"image\"]\n","resize_transform = transforms.Resize((224, 224), interpolation=2)\n","resize_transform(image)"],"id":"contained-billy","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"higher-child"},"source":["class Resize(Transform):\n","    def __init__(self, keys, size, interpolation=2):\n","        self.keys = keys\n","        self.resize = transforms.Resize(size, interpolation=interpolation)\n","\n","    def __call__(self, data):\n","        for key in self.keys:\n","            if key in data:\n","                image = data[key]\n","                data[key] = self.resize(image)\n","\n","            else:\n","                raise KeyError(f\"{key} is a key of {data}.\")\n","\n","        return data\n","\n","class PILToTensor(Transform):\n","    def __init__(self, keys):\n","        self.keys = keys\n","        self.to_tensor = transforms.ToTensor()\n","\n","    def __call__(self, data):\n","        for key in self.keys:\n","            if key in data:\n","                data[key] = self.to_tensor(data[key])\n","\n","            else:\n","                raise KeyError(f\"{key} is a key of {data}.\")\n","\n","        return data\n","\n","class NumpyToTensor(Transform):\n","    def __init__(self, keys):\n","        self.keys = keys\n","\n","    def __call__(self, data):\n","        for key in self.keys:\n","            if key in data:\n","                data[key] = torch.Tensor(data[key])\n","\n","            else:\n","                raise KeyError(f\"{key} is a key of {data}.\")\n","\n","        return data"],"id":"higher-child","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"criminal-heading","outputId":"891f6f4b-cc2f-4fff-80d2-65f58df4bd75"},"source":["transform = transforms.Compose([\n","    JPGLoader(keys=[\"image\"]),\n","    Resize(keys=[\"image\"], size=(224, 224), interpolation=2),\n","    PILToTensor(keys=[\"image\"]),\n","    NumpyToTensor(keys=[\"label\"])\n","])\n","dataset = RANZCR(data_root, csv_file, transform=transform)\n","\n","data = dataset[0]\n","print(data)\n","# for data in dataset[:2]:\n","#     print(data)\n","#     break"],"id":"criminal-heading","execution_count":null,"outputs":[{"output_type":"stream","text":["{'patient_id': 'ec89415d1', 'image': tensor([[[0.0157, 0.0157, 0.0157,  ..., 0.0392, 0.0392, 0.0353],\n","         [0.0588, 0.0588, 0.0549,  ..., 0.2000, 0.1922, 0.1725],\n","         [0.0510, 0.0549, 0.0510,  ..., 0.2471, 0.2353, 0.2157],\n","         ...,\n","         [0.2353, 0.2824, 0.2706,  ..., 0.5216, 0.4627, 0.3843],\n","         [0.2392, 0.2784, 0.2510,  ..., 0.5294, 0.4706, 0.3961],\n","         [0.2588, 0.2667, 0.2235,  ..., 0.4980, 0.4431, 0.3725]]]), 'label': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"foreign-sense","outputId":"d517c752-617d-4882-d575-67c7f4aa4a70"},"source":["data[\"label\"].shape"],"id":"foreign-sense","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([11])"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"careful-mystery"},"source":["### 1.5. DataLoader\n","DataLoader 是 Pytorch 一個很方便的物件，它直接幫你把 Dataset 變成可以 batch-wise 讀取的迭代器，同時實現平行化讀取。\n","\n","完整的 shape 應該是 $\\text{batch} \\times \\text{channels} \\times \\text{height} \\times \\text{width}$"],"id":"careful-mystery"},{"cell_type":"code","metadata":{"id":"dedicated-scout"},"source":["loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)"],"id":"dedicated-scout","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"diverse-collaboration"},"source":["# data = loader[0]\n","# print(data[\"image\"].shape)"],"id":"diverse-collaboration","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"macro-wrong","outputId":"97ec461f-9d1f-46ef-ba40-073072363416"},"source":["for data in loader:\n","    print(data[\"image\"].shape)\n","    break"],"id":"macro-wrong","execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 1, 224, 224])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"spectacular-vegetation"},"source":["# 2. Setup Hyperparameters"],"id":"spectacular-vegetation"},{"cell_type":"markdown","metadata":{"id":"union-transformation"},"source":["### 2.1. Model Construction\n","Pytorhc model 是一種 torch.nn.Module class，並且有定義 __init__, forward\n","* __init__ 用來存 parameters\n","* forward 吃一個 input x，你必須指明 x 會經過哪些運算，最後 output 出去\n","\n","##### Note.\n","但因為我幫你把 nn import 好了，所以你只需要寫 nn.Module 就可以使用它了"],"id":"union-transformation"},{"cell_type":"code","metadata":{"id":"incredible-backing"},"source":["class ExampleModel(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ExampleModel, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=4, padding=1)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=4, padding=1)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=4, padding=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.flat = nn.Flatten()\n","        self.linear = nn.Linear(256, out_channels)\n","        self.bn_out = nn.BatchNorm1d(out_channels)\n","\n","    def call(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = self.flat(x)\n","        x = F.sigmoid(self.bn_out(self.linear(x)))\n","\n","        return x"],"id":"incredible-backing","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"premium-mediterranean"},"source":["model = ExampleModel(1, 11)\n","model"],"id":"premium-mediterranean","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clean-slave"},"source":["x = torch.rand(32, 1, 128, 128)\n","y = model(x)\n","y.size()"],"id":"clean-slave","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"official-legislature"},"source":["class ExampleModel(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ExampleModel, self).__init__()\n","        # input 128 x 128\n","        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=4, padding=1) # 32 x 32\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=4, padding=1) # 8 x 8\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=4, padding=1) # 2 x 2\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.flat = nn.Flatten() # 64 x 2 x 2 = 256\n","        self.linear = nn.Linear(256, out_channels)\n","        self.bn_out = nn.BatchNorm1d(out_channels)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = self.flat(x)\n","        x = torch.sigmoid(self.bn_out(self.linear(x)))\n","\n","        return x"],"id":"official-legislature","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"precious-swiss"},"source":["model = ExampleModel(1, 11)\n","model"],"id":"precious-swiss","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"political-makeup"},"source":["x = torch.rand(32, 1, 128, 128)\n","y = model(x)\n","y.size()"],"id":"political-makeup","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quiet-declaration"},"source":["class ExampleModel(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ExampleModel, self).__init__()\n","        # input 224 x 224\n","        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=4, padding=1) # 56 x 56\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=4, padding=1) # 14 x 14\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0) # 12 x 12\n","        self.bn3 = nn.BatchNorm2d(32)\n","        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, stride=4, padding=1) # 3 x 3\n","        self.bn4 = nn.BatchNorm2d(64)\n","        self.flat = nn.Flatten() # 64 x 3 x 3 = 576\n","        self.linear = nn.Linear(576, out_channels)\n","        self.bn_out = nn.BatchNorm1d(out_channels)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = F.relu(self.bn4(self.conv4(x)))\n","        x = self.flat(x)\n","        x = torch.sigmoid(self.bn_out(self.linear(x)))\n","\n","        return x"],"id":"quiet-declaration","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"broken-serum"},"source":["model = ExampleModel(1, 11)\n","model"],"id":"broken-serum","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"breeding-specific"},"source":["x = torch.rand(32, 1, 224, 224)\n","y = model(x)\n","y.size()"],"id":"breeding-specific","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"turkish-convergence"},"source":["### 2.2. Optimizers and Losses"],"id":"turkish-convergence"},{"cell_type":"code","metadata":{"id":"civil-projection"},"source":["criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"],"id":"civil-projection","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"answering-connection"},"source":["### 2.3. GPU Acceleration\n","1. 指定 device\n","  * device = torch.cuda.device(\"cuda:0\" if torch.cuda.is_availabel() else \"cpu\")\n","2. 將 model, criterion, optimizer 放到 device\n","  * model.to(device)\n","  * criterion.to(device)\n","  * optimizer.to(device)"],"id":"answering-connection"},{"cell_type":"code","metadata":{"id":"filled-orbit","outputId":"244df114-6de2-4285-9a19-983f68424ff6"},"source":["\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\""],"id":"filled-orbit","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu:0'"]},"metadata":{"tags":[]},"execution_count":138}]},{"cell_type":"code","metadata":{"id":"temporal-coordinator"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\")\n","model = model.to(device)"],"id":"temporal-coordinator","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"suspected-crazy","outputId":"32143829-e60f-4bde-efaf-75f492805103"},"source":["next(model.parameters()).is_cuda"],"id":"suspected-crazy","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":136}]},{"cell_type":"markdown","metadata":{"id":"electrical-olive"},"source":["# 3. Training and Validation"],"id":"electrical-olive"},{"cell_type":"markdown","metadata":{"id":"similar-puppy"},"source":["### 3.1. Training Process\n","當我們的 data loader, model, criterion, optimizer 都設置好以後，接下來的 training process 就可以用底下幾個步驟概括了\n","\n","0. 清空 optimizer 的 gradient 及將 model 改為訓練模式\n","  * optimizer.zero_grad()\n","  * model.train()\n","1. 從 data loader 取得一組資料\n","  * 資料 input\n","  * 標註 target\n","2. 計算 model 的預測\n","  * output = model(input)\n","3. 計算 loss\n","  * loss = criterion(output, target)\n","4. 計算 gradient\n","  * loss.backward()\n","5. 更新參數\n","  * optimizer.step()"],"id":"similar-puppy"},{"cell_type":"markdown","metadata":{"id":"vocational-looking"},"source":["### 3.2. Your Turn!\n","這邊留給你們寫應該不過分吧XD"],"id":"vocational-looking"},{"cell_type":"code","metadata":{"id":"psychological-category","outputId":"810db9e5-e9a0-413e-db4d-848c39d30a82"},"source":["label.shape"],"id":"psychological-category","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 1, 1, 11])"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"sapphire-celebrity","outputId":"842c1471-986b-4230-c2ab-b552f19e64ae"},"source":["a = torch.Tensor([[1, 1], [1, 0]])\n","b = torch.Tensor([[1, 1], [1, 1]])\n","a"],"id":"sapphire-celebrity","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1.],\n","        [1., 0.]])"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"code","metadata":{"id":"searching-austin","outputId":"a37c28a9-a260-46b3-8465-b853fda60eb1"},"source":["b"],"id":"searching-austin","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1.],\n","        [1., 1.]])"]},"metadata":{"tags":[]},"execution_count":104}]},{"cell_type":"code","metadata":{"id":"answering-healing","outputId":"9ed30dd7-c072-464b-85d4-aa4fe3ea3759"},"source":["a == b"],"id":"answering-healing","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ True,  True],\n","        [ True, False]])"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"id":"opposed-thomas","outputId":"e1c9373f-9294-46d6-bde7-2227cee3b4a8"},"source":["n_correct = torch.sum(a == b, axis=0).double()\n","n_correct"],"id":"opposed-thomas","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2., 1.], dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"code","metadata":{"id":"conditional-jones","outputId":"ef601ece-9cf8-49d1-eebb-0c275820dcc3"},"source":["mean_correct = torch.mean(n_correct) / len(a)"],"id":"conditional-jones","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.7500, dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"boring-customs","outputId":"65fd63c2-3f21-4939-b499-86602fd83410"},"source":["len(torch.zeros([3, 2])), len(torch.zeros([2, 3]))"],"id":"boring-customs","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 2)"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"id":"dirty-reservation","outputId":"c1125868-e3da-4efd-c1ff-52f7b1753b32"},"source":["torch.mean(torch.sum((prob > 0.5) == label, axis=0).double()) / len(prob)"],"id":"dirty-reservation","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.5994, dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"presidential-reverse","outputId":"c2ed10b9-a330-42f6-e3ce-badd4ba1f3fc"},"source":["len(prob), len(label)"],"id":"presidential-reverse","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 32)"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"novel-armstrong"},"source":["def compute_accuracy(pred, label):\n","    n_correct = pred == label\n","    total_correct = torch.sum(n_correct, axis=0).double()\n","    mean_correct = torch.mean(total_correct)\n","\n","    return mean_correct / len(pred)"],"id":"novel-armstrong","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alternative-builder","outputId":"1bb01c72-de94-4239-e4cb-7afefdfb5e88"},"source":["# your code here\n","from sklearn.metrics import roc_auc_score\n","# 0.1.\n","model.train()\n","n_steps = len(loader)\n","\n","for i, data in enumerate(loader):\n","    # 0.2.\n","    optimizer.zero_grad()\n","    \n","    # 1.\n","    image = data[\"image\"]\n","    label = data[\"label\"]\n","\n","    # 2.\n","    prob = model(image)\n","\n","    # 3.\n","    loss = criterion(prob, label)\n","\n","    # 4.\n","    loss.backward()\n","\n","    # 5.\n","    optimizer.step()\n","\n","    # bonus\n","    acc = compute_accuracy(prob > 0.5, label)\n","\n","    print(f\"step [{i}, {n_steps}], loss = {loss.detach().numpy()}, acc = {acc.detach().numpy()}\")"],"id":"alternative-builder","execution_count":null,"outputs":[{"output_type":"stream","text":["step [0, 941], loss = 0.4702613055706024, acc = 0.8920454545454546\n","step [1, 941], loss = 0.49016091227531433, acc = 0.8806818181818182\n","step [2, 941], loss = 0.5011453628540039, acc = 0.8409090909090909\n","step [3, 941], loss = 0.4752653241157532, acc = 0.8721590909090909\n","step [4, 941], loss = 0.48357945680618286, acc = 0.8636363636363636\n","step [5, 941], loss = 0.48490336537361145, acc = 0.8522727272727273\n","step [6, 941], loss = 0.493107408285141, acc = 0.8522727272727273\n","step [7, 941], loss = 0.4924885034561157, acc = 0.8409090909090909\n","step [8, 941], loss = 0.5002603530883789, acc = 0.8352272727272727\n","step [9, 941], loss = 0.4823310971260071, acc = 0.8721590909090909\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-155-2992871be147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# 5.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# bonus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"moderate-emerald"},"source":["### 3.3. Validation Process\n","同上設置，我們有底下步驟\n","\n","0. 將 model 改為計算模式並且用 torch.no_grad() 包住整段 code\n","  * model.eval()\n","  * with torch.no_grad():\n","        ...\n","1. 從 data loader 取得一組資料\n","  * 資料 input\n","  * 標註 target\n","2. 計算 model 的預測\n","  * output = model(input)\n","3. 計算 loss 或你要的指標\n","  * loss = criterion(output, target)\n","  * metric = ...\n","4. 看你要 print 出來還是存到哪裡去都行"],"id":"moderate-emerald"},{"cell_type":"markdown","metadata":{"id":"armed-playing"},"source":["### 3.4. Your Turn!\n","就算你覺得過分我也不會理你 <3"],"id":"armed-playing"},{"cell_type":"code","metadata":{"id":"binding-abraham","outputId":"9506cfa4-0700-456c-d436-1cdb57dfabc7"},"source":["# your code here\n","\n","model.eval()\n","\n","with torch.no_grad():\n","    for data in loader:\n","        image = data[\"image\"]\n","        label = data[\"label\"]\n","\n","        prob = model(image)\n","        loss = criterion(prob, label)\n","\n","        print(f\"loss = {loss.detach().numpy()}\")"],"id":"binding-abraham","execution_count":null,"outputs":[{"output_type":"stream","text":["loss = 0.5063570141792297\n","loss = 0.5237624049186707\n","loss = 0.4740864038467407\n","loss = 0.5229761600494385\n","loss = 0.4966447651386261\n","loss = 0.5032168030738831\n","loss = 0.4962211847305298\n","loss = 0.49787452816963196\n","loss = 0.48986756801605225\n","loss = 0.4732462167739868\n","loss = 0.4749063551425934\n","loss = 0.48760679364204407\n","loss = 0.5086483955383301\n","loss = 0.5146855711936951\n","loss = 0.5227349400520325\n","loss = 0.5026934742927551\n","loss = 0.470589816570282\n","loss = 0.4690669775009155\n","loss = 0.48569098114967346\n","loss = 0.48486536741256714\n","loss = 0.5157176852226257\n","loss = 0.5140590071678162\n","loss = 0.4661915600299835\n","loss = 0.5472235679626465\n","loss = 0.5293269753456116\n","loss = 0.4919591248035431\n","loss = 0.5128269791603088\n","loss = 0.484343022108078\n","loss = 0.4893135130405426\n","loss = 0.5083281397819519\n","loss = 0.47075459361076355\n","loss = 0.5202732682228088\n","loss = 0.48119696974754333\n","loss = 0.4865117371082306\n","loss = 0.4798578917980194\n","loss = 0.48326605558395386\n","loss = 0.5060675144195557\n","loss = 0.474618136882782\n","loss = 0.45279884338378906\n","loss = 0.4693029522895813\n","loss = 0.5306379199028015\n","loss = 0.5086439251899719\n","loss = 0.47405654191970825\n","loss = 0.47956904768943787\n","loss = 0.49016502499580383\n","loss = 0.4948395788669586\n","loss = 0.5037755966186523\n","loss = 0.5056495070457458\n","loss = 0.48125869035720825\n","loss = 0.5082952976226807\n","loss = 0.5245002508163452\n","loss = 0.5555285811424255\n","loss = 0.48840075731277466\n","loss = 0.49671319127082825\n","loss = 0.5077648758888245\n","loss = 0.5211724042892456\n","loss = 0.5158020853996277\n","loss = 0.47718533873558044\n","loss = 0.48934051394462585\n","loss = 0.5177814364433289\n","loss = 0.4957500398159027\n","loss = 0.4779660105705261\n","loss = 0.48619699478149414\n","loss = 0.504507303237915\n","loss = 0.495404988527298\n","loss = 0.5099506974220276\n","loss = 0.5084801912307739\n","loss = 0.4855191111564636\n","loss = 0.4503125250339508\n","loss = 0.5127792954444885\n","loss = 0.5033590793609619\n","loss = 0.4803788959980011\n","loss = 0.5101720094680786\n","loss = 0.48462629318237305\n","loss = 0.4863879978656769\n","loss = 0.48727092146873474\n","loss = 0.5085700154304504\n","loss = 0.5370966196060181\n","loss = 0.46106722950935364\n","loss = 0.4859106242656708\n","loss = 0.48239144682884216\n","loss = 0.48803216218948364\n","loss = 0.477944552898407\n","loss = 0.48098671436309814\n","loss = 0.496134489774704\n","loss = 0.5037187933921814\n","loss = 0.4827836751937866\n","loss = 0.49404117465019226\n","loss = 0.5218380093574524\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-159-afefaeb125dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"fuzzy-indonesia"},"source":[""],"id":"fuzzy-indonesia","execution_count":null,"outputs":[]}]}