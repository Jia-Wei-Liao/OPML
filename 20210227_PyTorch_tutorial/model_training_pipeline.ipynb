{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"model_training_pipeline.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"short-claim"},"source":["# Import Packages"],"id":"short-claim"},{"cell_type":"code","metadata":{"id":"focal-folder"},"source":["import os, torch\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms"],"id":"focal-folder","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"musical-change"},"source":["# Setup"],"id":"musical-change"},{"cell_type":"code","metadata":{"id":"outside-ready"},"source":["csv_file = \"train.csv\"\n","data_list = pd.read_csv(csv_file)\n","data_root = \"train\"\n","file = \"{}.jpg\"\n","data_list"],"id":"outside-ready","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"marine-browse"},"source":["# 0. Pipeline Illustration\n","關於訓練模型，我們有幾個步驟要做：\n","1. 讀資料、建構 Dataset 及 DataLoader\n","2. 定義 model, optimizer, loss\n","3. training and validation"],"id":"marine-browse"},{"cell_type":"markdown","metadata":{"id":"significant-covering"},"source":["# 1. Load Data and Construct Dataset, DataLoader"],"id":"significant-covering"},{"cell_type":"markdown","metadata":{"id":"painful-writer"},"source":["### 1.1. Load JPG, JPEG, PNG\n","因為我們的影像是 JPEG 檔，所以我們來學如何讀這系列的檔案\n","\n","##### Note.\n","這系列の檔案類型都是色彩強度在 [0, 255] 的影像"],"id":"painful-writer"},{"cell_type":"code","metadata":{"id":"undefined-watson"},"source":["example_image = np.random.choice(data_list.StudyInstanceUID)\n","path = os.path.join(data_root, file.format(example_image))\n","path"],"id":"undefined-watson","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"competent-ensemble"},"source":["image = Image.open(path)\n","image"],"id":"competent-ensemble","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"chemical-dragon"},"source":["array = np.array(image)\n","print(f\"shape = {array.shape}\")\n","np.unique(array)"],"id":"chemical-dragon","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"amateur-consciousness"},"source":["### 1.2. Pytorch Dataset and DataLoader\n","Pytorch Dataset 是一種 iterable（熟悉吧？）\n","1. 它必須繼承 Pytorch 的 Dataset class\n","2. 是一個 iterable class，會一個一個吐出你的 data\n","\n","至於 data 要用什麼形式包裝他就不限制了。\n","不過我想給大家一個管理 data 的建議：一個 data 用一個 dictionary 包裝。"],"id":"amateur-consciousness"},{"cell_type":"code","metadata":{"id":"heated-spread"},"source":["example_index = 0\n","data = {\n","    \"patient_id\": data_list.iloc[example_index, -1],\n","    \"image\": data_list.iloc[example_index, 0],\n","    \"label\": np.array(data_list.iloc[example_index, 1:-1], dtype=\"float32\")\n","}\n","data"],"id":"heated-spread","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"horizontal-german"},"source":["### 1.3. Your Trun!\n","請你動手寫一個名為 RANZCR 的 Pytorch Dataset。\n","1. 繼承 torch.utils.data.Dataset (Hint: 在開頭的 import 環節，我已經幫你把它 import 成 Dataset 了，繼承 Dataset 並 initialize 就好）\n","2. initialize 兩個字串 data_root 和 csv_file（建議按照順序）\n","  * 把 csv_file 讀成 pandas DataFrame 作為 attribute\n","  * 直接把 data_root 存成字串，用來讀串接影像名稱\n","3. 用你的方式寫一個 iterable：\n","  * 放到迴圈時，每一次迭代吐一組資料（即一個 dictionary 如上）\n","  * 可以取長度\n","  * 可以多次放到迴圈裡面使用"],"id":"horizontal-german"},{"cell_type":"code","metadata":{"id":"modified-arthritis"},"source":["# your code here"],"id":"modified-arthritis","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"downtown-steam"},"source":["check_answer = False\n","\n","if check_answer:\n","    dataset = RANZCR(data_root, csv_file)\n","\n","    for data in dataset:\n","        print(data)\n","        break"],"id":"downtown-steam","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"above-campus"},"source":["### 1.4. Data Transform\n","你肯定注意到了，我們讀進來的資料只有檔名，不可能直接拿來 train。\n","這時我們需要一連串的 transforms 來讓資料從檔名開始經歷他的奇幻旅程，這中間你愛加多少 data augmentation 都隨你開心。"],"id":"above-campus"},{"cell_type":"code","metadata":{"id":"north-powder"},"source":["# 帶大家寫 Tranform 以及把 Dataset 修成有 transform 的版本"],"id":"north-powder","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cutting-worth"},"source":["### 1.5. DataLoader\n","DataLoader 是 Pytorch 一個很方便的物件，它直接幫你把 Dataset 變成可以 batch-wise 讀取的迭代器，同時實現平行化讀取。"],"id":"cutting-worth"},{"cell_type":"code","metadata":{"id":"compact-hindu"},"source":["loader = DataLoader(RANZCR, batch_size=32, shuffle=True, num_workers=0)"],"id":"compact-hindu","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"employed-contemporary"},"source":["# 2. Setup Hyperparameters"],"id":"employed-contemporary"},{"cell_type":"markdown","metadata":{"id":"alpine-holly"},"source":["### 2.1. Model Construction\n","Pytorhc model 是一種 torch.nn.Module class，並且有定義 __init__, forward\n","* __init__ 用來存 parameters\n","* forward 吃一個 input x，你必須指明 x 會經過哪些運算，最後 output 出去\n","\n","##### Note.\n","但因為我幫你把 nn import 好了，所以你只需要寫 nn.Module 就可以使用它了"],"id":"alpine-holly"},{"cell_type":"code","metadata":{"id":"noted-boards"},"source":["class ExampleModel(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ExampleModel, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=4, padding=1)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=4, padding=1)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=4, padding=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.flat = nn.Flatten()\n","        self.linear = nn.Linear(256, out_channels)\n","        self.bn_out = nn.BatchNorm1d(out_channels)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = self.flat(x)\n","        x = F.sigmoid(self.bn_out(self.linear(x)))\n","\n","        return x"],"id":"noted-boards","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"portable-poetry"},"source":["model = ExampleModel(1, 11)\n","model"],"id":"portable-poetry","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"addressed-accent"},"source":["x = torch.rand(32, 1, 128, 128)\n","y = model(x)\n","y.size()"],"id":"addressed-accent","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bigger-oakland"},"source":["### 2.2. Optimizers and Losses"],"id":"bigger-oakland"},{"cell_type":"code","metadata":{"id":"selective-arrow"},"source":["criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters())"],"id":"selective-arrow","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"olympic-passport"},"source":["# 3. Training and Validation"],"id":"olympic-passport"},{"cell_type":"markdown","metadata":{"id":"worse-confidentiality"},"source":["### 3.1. Training Process\n","當我們的 data loader, model, criterion, optimizer 都設置好以後，接下來的 training process 就可以用底下幾個步驟概括了\n","\n","0. 清空 optimizer 的 gradient 及將 model 改為訓練模式\n","  * optimizer.zero_grad()\n","  * model.train()\n","1. 從 data loader 取得一組資料\n","  * 資料 input\n","  * 標註 target\n","2. 計算 model 的預測\n","  * output = model(input)\n","3. 計算 loss\n","  * loss = criterion(output, target)\n","4. 計算 gradient\n","  * loss.backward()\n","5. 更新參數\n","  * optimizer.step()"],"id":"worse-confidentiality"},{"cell_type":"markdown","metadata":{"id":"fluid-divorce"},"source":["### 3.2. Your Turn!\n","這邊留給你們寫應該不過分吧XD"],"id":"fluid-divorce"},{"cell_type":"code","metadata":{"id":"together-criterion"},"source":["# your code here"],"id":"together-criterion","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sacred-orchestra"},"source":["### 3.3. Validation Process\n","同上設置，我們有底下步驟\n","0. 將 model 改為計算模式並且用 torch.no_grad() 包住整段 code\n","  * model.eval()\n","  * with torch.no_grad():\n","        ...\n","1. 從 data loader 取得一組資料\n","  * 資料 input\n","  * 標註 target\n","2. 計算 model 的預測\n","  * output = model(input)\n","3. 計算 loss 或你要的指標\n","  * loss = criterion(output, target)\n","  * metric = ...\n","4. 看你要 print 出來還是存到哪裡去都行1. 從 data loader 取得一組資料\n","  * 資料 input\n","  * 標註 target"],"id":"sacred-orchestra"},{"cell_type":"markdown","metadata":{"id":"dirty-airport"},"source":["### 3.4. Your Turn!\n","就算你覺得過分我也不會理你 <3"],"id":"dirty-airport"},{"cell_type":"code","metadata":{"id":"accessible-saturn"},"source":["# your code here"],"id":"accessible-saturn","execution_count":null,"outputs":[]}]}